###Usage
The Web Crawler takes three arguments through the command line:

1: a valid URL

2: a specified maximum page depth in the form of a natural integer. 

3: a file path to the desired local destination repository for the 
files to be downloaded by the crawler. 

For example: 
http://test.com, depth 3

###Building
